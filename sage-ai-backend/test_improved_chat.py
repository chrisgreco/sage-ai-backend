#!/usr/bin/env python3

"""
Test Script for Improved Chat API
=================================

Demonstrates the improvements:
1. Single agent responses (no simultaneous talking)
2. Persistent conversation memory
3. Intelligent agent selection
4. Context-aware responses
"""

import requests
import json
import time

API_BASE = "http://localhost:8001"

def send_message(message: str, room_id: str = "demo-room"):
    """Send a message to the chat API"""
    response = requests.post(
        f"{API_BASE}/api/chat/message",
        json={"message": message, "room_id": room_id}
    )
    return response.json()

def get_conversation_memory(room_id: str = "demo-room"):
    """Get the conversation memory"""
    response = requests.get(f"{API_BASE}/api/chat/memory/{room_id}")
    return response.json()

def main():
    print("ğŸ­ Testing Improved Sage AI Chat API")
    print("=" * 50)
    
    room_id = "demo-room"
    
    # Test 1: Single agent response
    print("\n1ï¸âƒ£ Testing single agent response...")
    result1 = send_message("humans are 2x stronger than apes", room_id)
    response1 = result1["response"]
    print(f"   ğŸ‘¤ User: humans are 2x stronger than apes")
    print(f"   ğŸ¤– {response1['agent_name']} ({response1['agent_role']}): {response1['message']}")
    print(f"   ğŸ“Š Conversation length: {result1['conversation_length']}")
    
    time.sleep(1)
    
    # Test 2: Follow-up question to test memory
    print("\n2ï¸âƒ£ Testing conversation memory...")
    result2 = send_message("aristotle can you cite your sources?", room_id)
    response2 = result2["response"]
    print(f"   ğŸ‘¤ User: aristotle can you cite your sources?")
    print(f"   ğŸ¤– {response2['agent_name']} ({response2['agent_role']}): {response2['message']}")
    print(f"   ğŸ“Š Conversation length: {result2['conversation_length']}")
    
    time.sleep(1)
    
    # Test 3: Different topic to test agent selection
    print("\n3ï¸âƒ£ Testing agent selection...")
    result3 = send_message("I feel conflicted about this issue", room_id)
    response3 = result3["response"]
    print(f"   ğŸ‘¤ User: I feel conflicted about this issue")
    print(f"   ğŸ¤– {response3['agent_name']} ({response3['agent_role']}): {response3['message']}")
    print(f"   ğŸ“Š Conversation length: {result3['conversation_length']}")
    
    # Test 4: Show conversation memory
    print("\n4ï¸âƒ£ Full conversation memory:")
    memory = get_conversation_memory(room_id)
    print(f"   ğŸ“š Total messages: {memory['message_count']}")
    for i, msg in enumerate(memory['conversation'], 1):
        speaker = msg['speaker'].title()
        print(f"   {i:2d}. {speaker}: {msg['message'][:60]}...")
    
    print("\nâœ… Key Improvements Demonstrated:")
    print("   â€¢ Only ONE agent responds per message (no chaos)")
    print("   â€¢ Conversation memory persists across requests")
    print("   â€¢ Intelligent agent selection based on content")
    print("   â€¢ Context-aware responses using conversation history")
    
    print("\nğŸ¯ Production Integration:")
    print("   â€¢ This API can integrate with LiveKit voice agents")
    print("   â€¢ Frontend can call these endpoints for real conversations")
    print("   â€¢ Memory system supports multi-user rooms")
    print("   â€¢ Turn-taking prevents simultaneous responses")

if __name__ == "__main__":
    try:
        main()
    except requests.exceptions.ConnectionError:
        print("âŒ Error: Could not connect to API. Make sure it's running on port 8001")
        print("Run: python integrated_chat_api.py")
    except Exception as e:
        print(f"âŒ Error: {e}") 